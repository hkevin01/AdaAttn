{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaAttn Research Quickstart\n",
    "\n",
    "This notebook provides a quick introduction to using AdaAttn for research.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('/workspace/AdaAttn/src')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# AdaAttn imports\n",
    "from adaattn.attention import AdaAttention, AdaptiveRankAttention, AdaptivePrecisionAttention, DenseAttention\n",
    "from adaattn.utils.research_logger import get_research_logger, log_metrics\n",
    "from adaattn.utils.research_monitor import create_monitor\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Attention Comparison\n",
    "\n",
    "Let's compare different attention mechanisms on a simple task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup experiment parameters\n",
    "batch_size = 4\n",
    "seq_len = 512\n",
    "hidden_size = 512\n",
    "num_heads = 8\n",
    "\n",
    "# Create sample data\n",
    "query = torch.randn(batch_size, seq_len, hidden_size, device=device)\n",
    "key = torch.randn(batch_size, seq_len, hidden_size, device=device)\n",
    "value = torch.randn(batch_size, seq_len, hidden_size, device=device)\n",
    "\n",
    "print(f\"Input shape: {query.shape}\")\n",
    "\n",
    "# Initialize different attention mechanisms\n",
    "attention_configs = {\n",
    "    'Dense': DenseAttention(hidden_size, num_heads),\n",
    "    'AdaptiveRank': AdaptiveRankAttention(hidden_size, num_heads, rank_ratio=0.5),\n",
    "    'AdaptivePrecision': AdaptivePrecisionAttention(hidden_size, num_heads),\n",
    "    'AdaAttention': AdaAttention(hidden_size, num_heads, enable_gpu_optimization=torch.cuda.is_available())\n",
    "}\n",
    "\n",
    "# Move to device\n",
    "for name, attention in attention_configs.items():\n",
    "    attention_configs[name] = attention.to(device)\n",
    "\n",
    "print(\"Attention mechanisms initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Performance Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "# Benchmark each attention mechanism\n",
    "results = defaultdict(list)\n",
    "num_runs = 10\n",
    "\n",
    "for name, attention in attention_configs.items():\n",
    "    attention.eval()\n",
    "    \n",
    "    print(f\"Benchmarking {name}...\")\n",
    "    \n",
    "    # Warm up\n",
    "    for _ in range(3):\n",
    "        with torch.no_grad():\n",
    "            _ = attention(query, key, value)\n",
    "    \n",
    "    # Benchmark\n",
    "    times = []\n",
    "    memories = []\n",
    "    \n",
    "    for run in range(num_runs):\n",
    "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.reset_max_memory_allocated()\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = attention(query, key, value)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        times.append(end_time - start_time)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            memories.append(torch.cuda.max_memory_allocated() / 1024**3)  # GB\n",
    "        else:\n",
    "            memories.append(0)\n",
    "    \n",
    "    results[name] = {\n",
    "        'mean_time': np.mean(times),\n",
    "        'std_time': np.std(times),\n",
    "        'mean_memory': np.mean(memories),\n",
    "        'output_shape': list(output.shape)\n",
    "    }\n",
    "    \n",
    "    print(f\"  Mean time: {np.mean(times)*1000:.2f} ± {np.std(times)*1000:.2f} ms\")\n",
    "    print(f\"  Mean memory: {np.mean(memories):.3f} GB\")\n",
    "\n",
    "print(\"\\nBenchmarking complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison plots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Time comparison\n",
    "names = list(results.keys())\n",
    "times = [results[name]['mean_time'] * 1000 for name in names]  # Convert to ms\n",
    "time_errors = [results[name]['std_time'] * 1000 for name in names]\n",
    "\n",
    "ax1.bar(names, times, yerr=time_errors, capsize=5, alpha=0.7)\n",
    "ax1.set_ylabel('Time (ms)')\n",
    "ax1.set_title('Attention Mechanism Performance')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Memory comparison\n",
    "memories = [results[name]['mean_memory'] for name in names]\n",
    "ax2.bar(names, memories, alpha=0.7, color='orange')\n",
    "ax2.set_ylabel('Memory (GB)')\n",
    "ax2.set_title('Memory Usage Comparison')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary table\n",
    "print(\"\\n=== Performance Summary ===\")\n",
    "print(f\"{'Attention Type':<20} {'Time (ms)':<12} {'Memory (GB)':<12} {'Speedup':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "baseline_time = results['Dense']['mean_time']\n",
    "for name in names:\n",
    "    time_ms = results[name]['mean_time'] * 1000\n",
    "    memory_gb = results[name]['mean_memory']\n",
    "    speedup = baseline_time / results[name]['mean_time']\n",
    "    \n",
    "    print(f\"{name:<20} {time_ms:<12.2f} {memory_gb:<12.3f} {speedup:<10.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Adaptive Behavior Analysis\n",
    "\n",
    "Let's analyze the adaptive behavior of AdaAttention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logger for detailed analysis\n",
    "logger = get_research_logger(\n",
    "    experiment_name=\"adaptive_behavior_analysis\",\n",
    "    log_dir=\"/workspace/logs\",\n",
    "    enable_tensorboard=True\n",
    ")\n",
    "\n",
    "print(\"Starting adaptive behavior analysis...\")\n",
    "\n",
    "# Test AdaAttention with different input patterns\n",
    "ada_attention = AdaAttention(hidden_size, num_heads, enable_gpu_optimization=torch.cuda.is_available()).to(device)\n",
    "ada_attention.eval()\n",
    "\n",
    "# Create different input patterns\n",
    "patterns = {\n",
    "    'random': torch.randn(batch_size, seq_len, hidden_size, device=device),\n",
    "    'structured': torch.zeros(batch_size, seq_len, hidden_size, device=device),\n",
    "    'sparse': torch.randn(batch_size, seq_len, hidden_size, device=device) * 0.1\n",
    "}\n",
    "\n",
    "# Make structured pattern\n",
    "patterns['structured'][:, :seq_len//4] = 1.0\n",
    "patterns['structured'][:, seq_len//2:3*seq_len//4] = -1.0\n",
    "\n",
    "adaptation_stats = {}\n",
    "\n",
    "for pattern_name, pattern_input in patterns.items():\n",
    "    print(f\"\\nAnalyzing {pattern_name} pattern...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = ada_attention(pattern_input, pattern_input, pattern_input)\n",
    "    \n",
    "    # Get adaptation statistics\n",
    "    if hasattr(ada_attention, 'get_statistics'):\n",
    "        stats = ada_attention.get_statistics()\n",
    "        adaptation_stats[pattern_name] = stats\n",
    "        \n",
    "        print(f\"  Low-rank usage: {stats.get('low_rank_usage', 0):.1%}\")\n",
    "        print(f\"  Precision distribution: {stats.get('precision_distribution', {})}\")\n",
    "        \n",
    "        # Log to research logger\n",
    "        logger.log_metrics(\n",
    "            custom_metrics={\n",
    "                f\"pattern/{pattern_name}/low_rank_usage\": stats.get('low_rank_usage', 0),\n",
    "                f\"pattern/{pattern_name}/mean_entropy\": stats.get('mean_entropy', 0)\n",
    "            }\n",
    "        )\n",
    "\n",
    "print(\"\\nAdaptive behavior analysis complete!\")\n",
    "print(\"Check TensorBoard for detailed metrics: http://localhost:6006\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Real-time Monitoring Example\n",
    "\n",
    "This shows how to use the monitoring system during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a training loop with monitoring\n",
    "print(\"Simulating training with real-time monitoring...\")\n",
    "\n",
    "# Note: In a real scenario, you'd start the monitor in a separate process\n",
    "# monitor = create_monitor(\"training_simulation\")\n",
    "\n",
    "# Simulate training epochs\n",
    "num_epochs = 5\n",
    "steps_per_epoch = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for step in range(steps_per_epoch):\n",
    "        # Simulate forward pass\n",
    "        with torch.no_grad():\n",
    "            output = ada_attention(query, key, value)\n",
    "        \n",
    "        # Simulate loss calculation\n",
    "        fake_loss = 1.0 - (epoch * steps_per_epoch + step) * 0.01 + np.random.normal(0, 0.05)\n",
    "        fake_accuracy = 0.5 + (epoch * steps_per_epoch + step) * 0.01 + np.random.normal(0, 0.02)\n",
    "        \n",
    "        epoch_loss += fake_loss\n",
    "        \n",
    "        # Log metrics\n",
    "        logger.log_metrics(\n",
    "            epoch=epoch,\n",
    "            step=epoch * steps_per_epoch + step,\n",
    "            loss=fake_loss,\n",
    "            accuracy=fake_accuracy,\n",
    "            learning_rate=0.001 * (0.9 ** epoch)\n",
    "        )\n",
    "        \n",
    "        if step % 3 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Step {step+1}/{steps_per_epoch}: \"\n",
    "                  f\"Loss = {fake_loss:.4f}, Acc = {fake_accuracy:.3f}\")\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} complete. Average loss: {epoch_loss/steps_per_epoch:.4f}\")\n",
    "\n",
    "print(\"\\nTraining simulation complete!\")\n",
    "print(\"Metrics logged to TensorBoard and research logger.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Research Configuration Management\n",
    "\n",
    "Learn how to manage experiment configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# Create a research configuration\n",
    "config = {\n",
    "    'experiment': {\n",
    "        'name': 'notebook_experiment_demo',\n",
    "        'description': 'Demonstration experiment from Jupyter notebook',\n",
    "        'tags': ['demo', 'notebook', 'research']\n",
    "    },\n",
    "    'model': {\n",
    "        'hidden_size': hidden_size,\n",
    "        'num_heads': num_heads,\n",
    "        'max_seq_len': seq_len,\n",
    "        'dropout': 0.1\n",
    "    },\n",
    "    'attention': {\n",
    "        'type': 'adaattn',\n",
    "        'enable_gpu_optimization': torch.cuda.is_available(),\n",
    "        'rank_adaptation': {\n",
    "            'enabled': True,\n",
    "            'rank_ratio': 0.5,\n",
    "            'entropy_threshold': 0.5\n",
    "        },\n",
    "        'precision_adaptation': {\n",
    "            'enabled': True,\n",
    "            'policy': 'balanced'\n",
    "        }\n",
    "    },\n",
    "    'logging': {\n",
    "        'level': 'INFO',\n",
    "        'log_attention_stats': True,\n",
    "        'log_gpu_memory': True\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save configuration\n",
    "config_dir = Path('/workspace/configs')\n",
    "config_dir.mkdir(exist_ok=True)\n",
    "\n",
    "config_file = config_dir / 'notebook_demo.yaml'\n",
    "with open(config_file, 'w') as f:\n",
    "    yaml.dump(config, f, indent=2)\n",
    "\n",
    "print(f\"Configuration saved to: {config_file}\")\n",
    "print(\"\\nConfiguration content:\")\n",
    "print(yaml.dump(config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Next Steps\n",
    "\n",
    "This notebook showed you the basics of AdaAttn research. Here's what you can do next:\n",
    "\n",
    "1. **Use the CLI tool**: Run `python scripts/research_cli.py` for interactive research\n",
    "2. **Docker Environment**: Use `docker-compose up` for full research setup\n",
    "3. **TensorBoard**: Visit http://localhost:6006 to see logged metrics\n",
    "4. **Custom Experiments**: Create your own configurations and experiments\n",
    "5. **Real Training**: Apply AdaAttn to your own models and datasets\n",
    "\n",
    "### Research Tips:\n",
    "\n",
    "- Use GPU when available for best performance\n",
    "- Monitor adaptive behavior across different input patterns\n",
    "- Compare against baseline attention for your specific tasks\n",
    "- Log everything - TensorBoard integration makes analysis easy\n",
    "- Use the real-time monitoring for long training runs\n",
    "\n",
    "### Documentation:\n",
    "\n",
    "- Check `docs/` for detailed documentation\n",
    "- See `examples/` for more advanced usage patterns\n",
    "- Use `configs/` to manage experiment configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "if logger:\n",
    "    logger.cleanup()\n",
    "\n",
    "print(\"�� Research quickstart complete!\")\n",
    "print(\"Ready to start your adaptive attention research!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
